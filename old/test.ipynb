{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My         ADJ                  \n",
      "name       NOUN                 \n",
      "is         VERB                 \n",
      "Rachmiel   PROPN      PERSON    \n",
      "and        CCONJ                \n",
      "I          PRON                 \n",
      "would      VERB                 \n",
      "like       VERB                 \n",
      "to         PART                 \n",
      "apply      VERB                 \n",
      "for        ADP                  \n",
      "3          NUM        DATE      \n",
      "days       NOUN       DATE      \n",
      "leave      VERB                 \n",
      "due        ADP                  \n",
      "to         ADP                  \n",
      "a          DET                  \n",
      "sore       ADJ                  \n",
      "throat     NOUN                 \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp('My name is Rachmiel and I would like to apply for 3 days leave due to a sore throat')\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{10}} {token.ent_type_:{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sick for 3 days 3 days three days\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">I am sick for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    3 days 3 days three days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 days 3 days three days\n",
      "WHATS GOING ON\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from spacy import displacy\n",
    "\n",
    "def get_date(offset = 0):\n",
    "    return datetime.now() + timedelta(days = offset)\n",
    "\n",
    "offset = 0\n",
    "\n",
    "responses = {\n",
    "    \"PERSON\": \"Hi [PERSON]!\",\n",
    "    \"ORG\": \"Tell me more about [ORG].\",\n",
    "    \"LOC\": \"I've heard of [LOC].\",\n",
    "    \"DATE\": f\"Please confirm you will be on 3 days MC from {get_date(): %B %d} to {get_date(offset): %B %d}\",\n",
    "    \"default\": \"I'm not sure I understand.\"\n",
    "}\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Process user input\n",
    "    doc = nlp(user_input)\n",
    "    print(doc)\n",
    "\n",
    "    displacy.render(doc, style='ent', jupyter=True, options={'distance': 110})\n",
    "\n",
    "    main_response = ''\n",
    "\n",
    "    # Extract named entities and choose a response\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text)\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            print(ent.label_)\n",
    "            main_response = main_response + responses.get(\"PERSON\")\n",
    "            main_response.replace(\"[{}]\".format(ent.label_), ent.text)\n",
    "        elif ent.label_ == \"DATE\" and ent.text.isnumeric():\n",
    "            offset = int(ent.text)\n",
    "            main_response = main_response + responses.get(\"DATE\")\n",
    "            main_response.replace(\"[{}]\".format(ent.label_), ent.text)\n",
    "        if main_response.isspace():\n",
    "            main_response = responses.get(\"DEFAULT\")\n",
    "    print(main_response + 'WHATS GOING ON')\n",
    "\n",
    "print(\"Goodbye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reporting_officer</th>\n",
       "      <th>hod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rachmiel Teo Ren Xiang</td>\n",
       "      <td>fong_chee_kiang@go.edu.sg</td>\n",
       "      <td>lim_zong_han@go.edu.sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name          reporting_officer                     hod\n",
       "0  Rachmiel Teo Ren Xiang  fong_chee_kiang@go.edu.sg  lim_zong_han@go.edu.sg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('users.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{\"LIKE_NUM\": True}, {\"LOWER\": {\"IN\": [\"day\", \"days\"]}}]\n",
    "matcher.add(\"DAYS_PATTERN\", [pattern])\n",
    "\n",
    "doc = nlp(\"I am sick for 3 days\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(match_id, start, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regex instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = re.compile(r'\\bon(?: [\\w\\d]+)* (leave|mc|appointment)\\b', re.IGNORECASE)\n",
    "\n",
    "# matcher.add('absent_pattern', [absent_pattern])\n",
    "\n",
    "text = \"\"\"\n",
    "I will be on leave from Monday to Friday\n",
    "I will be on medical leave from Monday to Friday\n",
    "I will be on a 3 day mc from tomorrow\n",
    "I will be on mc tomorrow\n",
    "\"\"\"\n",
    "\n",
    "matches = pattern.finditer(text)\n",
    "\n",
    "for match in matches:\n",
    "    print(f\"Match found: {match.group()}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
