{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "print(sys.path)\n",
    "from sheet_manager import SpreadsheetManager\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from utilities import current_sg_time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv('../.env.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Run the system command and capture the output\n",
    "    result = subprocess.run(['systemctl', 'status', 'postgresql'], \n",
    "                            stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.PIPE,\n",
    "                            text=True)\n",
    "    print(result.stdout)\n",
    "    # Check if PostgreSQL is active\n",
    "    if 'inactive (dead)' in result.stdout:\n",
    "        print(\"PostgreSQL service is inactive.\")\n",
    "    # else:\n",
    "    #     result = subprocess.run(['systemctl', 'stop', 'postgresql'],\n",
    "    #                         stdout=subprocess.PIPE, \n",
    "    #                         stderr=subprocess.PIPE,\n",
    "    #                         text=True)\n",
    "    #     print(\"PostgreSQL service stopped.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from contextlib import closing\n",
    "\n",
    "def execute_cmd(cmd):\n",
    "    try:\n",
    "        with closing(psycopg2.connect(dbname='chatbot', user=os.environ.get('SQL_USER'), password=os.environ.get('PGPASSWORD'), host='localhost', port=os.environ.get('SQL_PORT'))) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(cmd)\n",
    "                rows = cur.fetchall()\n",
    "                col_names = [desc[0] for desc in cur.description]\n",
    "                print(\"Connection to the database was successful\")\n",
    "                # Process your rows here\n",
    "                return rows, col_names\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_rows, users_col_names = execute_cmd(\"SELECT * FROM users;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['name', 'alias', 'number', 'dept', 'reporting_officer_name', 'is_global_admin', 'is_dept_admin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "db_users = pd.DataFrame(users_rows, columns=users_col_names)\n",
    "db_users = db_users[col_order]\n",
    "db_users.sort_values(by=\"name\", inplace=True)\n",
    "db_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_TABLE_URL = f\"https://graph.microsoft.com/v1.0/drives/{os.environ.get('DRIVE_ID')}/items/{os.environ.get('USERS_FILE_ID')}/workbook/worksheets/MainTable/tables/MainTable/rows\"\n",
    "\n",
    "with open(\"../token.txt\", 'r') as f:\n",
    "    token = f.read()\n",
    "\n",
    "header = {\n",
    "    'Authorization': token,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.get(url=USERS_TABLE_URL, headers=header)\n",
    "\n",
    "data = [tuple(info) for object_info in response.json()['value'] for info in object_info['values']]\n",
    "az_users = pd.DataFrame(data=data, columns=[\"name\", \"alias\", \"number\", \"dept\", \"reporting_officer_name\", \"access\"])\n",
    "az_users['is_global_admin'] = (az_users['access'] == 'GLOBAL')\n",
    "az_users['is_dept_admin'] = (az_users['access'] == 'DEPT')\n",
    "az_users.drop(columns=[\"access\"])\n",
    "az_users.sort_values(by=\"name\", inplace=True)\n",
    "az_users = az_users[col_order]\n",
    "az_users = az_users.replace({np.nan: None, \"\": None})\n",
    "az_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = az_users.equals(db_users)\n",
    "\n",
    "if exact_match:\n",
    "    print(\"no changes\")\n",
    "\n",
    "else:\n",
    "    print(\"changes made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(az_users, db_users, how=\"outer\", indicator=True)\n",
    "old_data_names = merged_data[merged_data['_merge'] == 'right_only']['name']\n",
    "new_data_names = merged_data[merged_data['_merge'] == 'left_only']['name']\n",
    "\n",
    "old_data = db_users.loc[(db_users['name'].isin(old_data_names) | db_users['reporting_officer_name'].isin(old_data_names))]\n",
    "old_data = old_data.replace({np.nan: None})\n",
    "\n",
    "new_data = az_users.loc[(az_users['name'].isin(new_data_names) | az_users['reporting_officer_name'].isin(new_data_names))]\n",
    "new_data = new_data.replace({np.nan: None})\n",
    "\n",
    "old_users_tuples = [name for name in old_data['name']]\n",
    "new_users_tuples = [tuple(new_user) for new_user in new_data.values]\n",
    "\n",
    "print(f\"Old users: {old_data['name'].values}\")\n",
    "print(f\"New users: {new_data['name'].values}\")\n",
    "\n",
    "display(old_data)\n",
    "display(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_rows, leave_col_names = execute_cmd(\"SELECT date, users.name, users.dept, job_leave.leave_type FROM leave_records JOIN job ON job.job_no = leave_records.job_no JOIN job_user ON job.job_no = job_user.job_no JOIN users ON job_user.name = users.name JOIN job_leave ON job.job_no = job_leave.job_no WHERE leave_records.is_cancelled = False;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_records_df = pd.DataFrame(leave_rows, columns=leave_col_names)\n",
    "# mc_records_df = mc_records_df[mc_records_df['is_cancelled'] != True]\n",
    "mc_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_order = ('Corporate', 'ICT', 'AP', 'Voc Ed', 'Lower Pri', 'Upper Pri', 'Secondary', 'High School', 'Relief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = mc_records_df.groupby(\"dept\")\n",
    "\n",
    "dept_dfs = []\n",
    "\n",
    "for (dept, data) in groups:\n",
    "    print(dept)\n",
    "    print(data)\n",
    "    dept_admins, dept_admins_col_names = execute_cmd(f\"SELECT * FROM users WHERE dept = '{dept}' AND is_dept_admin = True;\")\n",
    "    dept_admins_df = pd.DataFrame(dept_admins, columns=dept_admins_col_names)\n",
    "    dept_dfs.append(dept_admins_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dept_dfs:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
