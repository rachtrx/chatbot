{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import sqlite3\n",
    "\n",
    "sh_users = pd.read_excel('users.xlsx')\n",
    "sh_users.sort_values(by=\"name\", inplace=True)\n",
    "\n",
    "conn = sqlite3.connect('users.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('SELECT * FROM users ORDER BY name ASC')\n",
    "db_users = cursor.fetchall()\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "db_users = pd.DataFrame(db_users, columns=column_names)\n",
    "\n",
    "sh_users.info(), db_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = sh_users.equals(db_users)\n",
    "\n",
    "if not exact_match:\n",
    "    # create 2 dataframes to compare\n",
    "    old_users = pd.merge(sh_users, db_users, how=\"outer\", indicator=True).query('_merge == \"right_only\"').drop(columns='_merge')\n",
    "    new_users = pd.merge(sh_users, db_users, how=\"outer\", indicator=True).query('_merge == \"left_only\"').drop(columns='_merge')\n",
    "\n",
    "db_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_users_tuples = [tuple(old_user) for old_user in old_users.values]\n",
    "new_users_tuples = [tuple(new_user) for new_user in new_users.values]\n",
    "\n",
    "conn = sqlite3.connect('users.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for name, number, email, reporting_officer, hod in old_users_tuples:\n",
    "    cursor.execute('DELETE FROM users WHERE name = ?', (name,))\n",
    "    \n",
    "for name, number, email, reporting_officer, hod in new_users_tuples:\n",
    "    cursor.execute('INSERT INTO users (name, number, email, reporting_officer, hod) VALUES (?, ?, ?, ?, ?)', (name, number, email, reporting_officer, hod))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "class AzureSyncError(Exception):\n",
    "\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "\n",
    "def cur_datetime(dt_type):\n",
    "    return datetime.datetime.now().strftime(dt_type)\n",
    "\n",
    "def get_filename():\n",
    "    cur_date = datetime.datetime.now()\n",
    "    format_date = cur_date.strftime(\"%Y\")\n",
    "\n",
    "    return format_date\n",
    "\n",
    "template_path = os.path.join(os.path.dirname(os.getcwd()), 'excel_files', 'mc_template.xlsx')\n",
    "\n",
    "drive_url = f\"https://graph.microsoft.com/v1.0/drives/{os.environ.get('DRIVE_ID')}\"\n",
    "\n",
    "folder_url = drive_url + f\"/items/{os.environ.get('FOLDER_ID')}\"\n",
    "\n",
    "book_path = folder_url + f\"/children?$filter=name eq '{get_filename()}.xlsx'\"\n",
    "create_book_url = folder_url + f\":/{get_filename()}.xlsx:/content\"\n",
    "\n",
    "config = {\n",
    "    'client_id': os.environ.get('CLIENT_ID'),\n",
    "    'client_secret': os.environ.get('CLIENT_SECRET'),\n",
    "    'authority': os.environ.get('AUTHORITY'),\n",
    "    'scope': [os.environ.get('SCOPE')],\n",
    "    'site_id': os.environ.get('SITE_ID'),\n",
    "}\n",
    "\n",
    "headers = {\n",
    "        'Authorization': f'Bearer {os.environ.get(\"ACCESS_TOKEN\")}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def get_table_url(worksheet_url):\n",
    "\n",
    "    tables_url = f\"{worksheet_url}/tables\"\n",
    "    print(tables_url)\n",
    "\n",
    "\n",
    "    # get the tables\n",
    "    response = requests.get(url=tables_url, headers=headers)\n",
    "    if not 200 <= response.status_code < 300:\n",
    "        raise AzureSyncError(f\"Could not get the tables. {response.json()}\")\n",
    "\n",
    "    # if table not found, add_table() creates one\n",
    "    tables = response.json()['value']\n",
    "\n",
    "    table_ids = {table_obj[\"name\"]: table_obj['id'] for table_obj in response.json()['value']}\n",
    "    \n",
    "    if cur_datetime(\"%B\") not in table_ids.keys():\n",
    "        table_id = add_table(worksheet_url, cur_datetime(\"%B\"))\n",
    "    # if table found, get the id\n",
    "    else:\n",
    "        table_id = table_ids[f\"{cur_datetime('%B')}\"]\n",
    "        \n",
    "    table_url = f\"{tables_url}/{table_id}\"\n",
    "\n",
    "    return table_url\n",
    "\n",
    "def add_table(worksheet_url, name):\n",
    "\n",
    "    # ADD TABLE HEADERS\n",
    "    table_headers_url = f\"{worksheet_url}/range(address='A1:B1')\"\n",
    "\n",
    "    header_values = {\n",
    "        \"values\": [[\"Name\", \"Date\"]]\n",
    "    }\n",
    "\n",
    "    response = requests.patch(table_headers_url, headers=headers, json=header_values)\n",
    "    if not 200 <= response.status_code < 300:\n",
    "        raise AzureSyncError(f\"Table headers could not be initialised. {response.json()}\")\n",
    "\n",
    "    # ADD TABLE\n",
    "    add_table_url = f\"{worksheet_url}/tables/add\"\n",
    "\n",
    "    body = {\n",
    "        \"address\": \"A1:B1\",\n",
    "        \"hasHeaders\": True,\n",
    "    }\n",
    "\n",
    "    response = requests.post(add_table_url, headers=headers, json=body)\n",
    "    if not 200 <= response.status_code < 300:\n",
    "        raise AzureSyncError(f\"Table itself could not be initialised. {response.json()}\")\n",
    "    table_id = response.json()['id']\n",
    "\n",
    "    # CHANGE TABLE NAME\n",
    "    change_tablename_url = f\"{worksheet_url}/tables/{table_id}\"\n",
    "\n",
    "    table_options = {\n",
    "        \"name\": name\n",
    "    }\n",
    "\n",
    "    response = requests.patch(change_tablename_url, headers=headers, json=table_options)\n",
    "    if not 200 <= response.status_code < 300:\n",
    "        raise AzureSyncError(f\"Table name could not be changed. There might be tables with duplicate names {response.json()}\")\n",
    "\n",
    "    # return table\n",
    "    table_id = response.json()['id'] \n",
    "\n",
    "    return table_id\n",
    "\n",
    "def add_worksheet(worksheets_url, name):\n",
    "\n",
    "\n",
    "    body = {\n",
    "        \"name\": f\"{name}\"\n",
    "    }\n",
    "\n",
    "    # add the worksheet\n",
    "    response = requests.post(url=f\"{worksheets_url}/add\", headers=headers, json=body)\n",
    "\n",
    "    if 200 <= response.status_code < 300:\n",
    "        print(\"sheet added successfully!\")\n",
    "        worksheet_id = response.json()['id']\n",
    "    else:\n",
    "        raise AzureSyncError(f\"Sheet failed to add. Status code: {response.status_code}\")\n",
    "        print(response.json())\n",
    "\n",
    "    return worksheet_id\n",
    "\n",
    "def get_sheet_url(worksheets_url):\n",
    "\n",
    "    # get the worksheet names\n",
    "    response = requests.get(url=worksheets_url, headers=headers)\n",
    "\n",
    "    # if ws not found, add_worksheet() creates one\n",
    "\n",
    "    # get the worksheet names\n",
    "    response = requests.get(url=worksheets_url, headers=headers)\n",
    "\n",
    "    ws_ids = {sheet_obj[\"name\"]: sheet_obj['id'] for sheet_obj in response.json()['value']}\n",
    "    \n",
    "    if cur_datetime('%B') not in ws_ids.keys():\n",
    "        ws_id = add_worksheet(worksheets_url, cur_datetime(\"%B\"))\n",
    "    # if ws found, get the id\n",
    "    else:\n",
    "        ws_id = ws_ids[f\"{cur_datetime('%B')}\"]\n",
    "        \n",
    "    worksheet_url = f\"{worksheets_url}/{ws_id}\"\n",
    "\n",
    "    return worksheet_url\n",
    "\n",
    "def write_to_excel(write = True): #TODO add params\n",
    "\n",
    "    new_book = False\n",
    "\n",
    "\n",
    "    try:\n",
    "        # get the workbook for this month\n",
    "        cur_book = requests.get(url=book_path, headers=headers) \n",
    "\n",
    "        file_name = cur_book.json()['value']\n",
    "        if not file_name:\n",
    "            new_book = True\n",
    "            book_id = create_book()\n",
    "        else:\n",
    "            book_id = file_name[0]['id']\n",
    "\n",
    "        print(book_id)\n",
    "\n",
    "        worksheets_url = drive_url + f\"/items/{book_id}/workbook/worksheets\"\n",
    "\n",
    "        # checks if sheet for this month exists, otherwise create it\n",
    "        worksheet_url = get_sheet_url(worksheets_url)\n",
    "        print(f\"Worksheet URL FINAL = {worksheet_url}\")\n",
    "\n",
    "        table_url = get_table_url(worksheet_url)\n",
    "        print(f\"Table URL FINAL = {table_url}\")\n",
    "\n",
    "        if write is not False:\n",
    "\n",
    "            # delete Sheet1\n",
    "            if new_book == True:\n",
    "                deleteSheet1(worksheets_url)\n",
    "\n",
    "            # write to file\n",
    "            write_to_table_url = f\"{table_url}/rows\"\n",
    "\n",
    "            body = {\n",
    "                \"values\": [\n",
    "                    [\"Rachmiel\", \"'11/11/2023\"],\n",
    "                    [\"Shawn\", \"'11/11/2023\"],\n",
    "                    [\"Rachmiel\", \"'12/11/2023\"],\n",
    "                    [\"Tymothy\", \"'12/11/2023\"]\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            response = requests.post(write_to_table_url, headers= headers, json = body)\n",
    "\n",
    "            if 200 <= response.status_code < 300:\n",
    "                print(\"Data uploaded successfully!\")\n",
    "            else:\n",
    "                raise AzureSyncError(f\"Failed to upload data. Status code: {response.status_code}, {response.json()}\")\n",
    "        \n",
    "        return table_url\n",
    "        \n",
    "\n",
    "    except AzureSyncError as e:\n",
    "        print(e.message)\n",
    "        return\n",
    "\n",
    "def create_book():\n",
    "\n",
    "    with open(template_path, 'rb') as file_data:\n",
    "\n",
    "        # uploads the file\n",
    "        response = requests.put(create_book_url, headers=headers, data=file_data) \n",
    "\n",
    "    if 200 <= response.status_code < 300:\n",
    "        print(\"File added successfully!\")\n",
    "        book_id = response.json()['id']\n",
    "        return book_id\n",
    "    else:\n",
    "        raise AzureSyncError(f\"Failed to upload file. Status code: {response.status_code}, {response.json()}\")\n",
    "    \n",
    "\n",
    "def deleteSheet1(worksheets_url):\n",
    "\n",
    "    del_sheet1_url = worksheets_url + \"/Sheet1\"\n",
    "\n",
    "    # delete the sheet\n",
    "    response = requests.delete(del_sheet1_url, headers=headers)\n",
    "    if 200 <= response.status_code < 300:\n",
    "        print(\"Sheet successfully deleted\")\n",
    "        return\n",
    "    else:\n",
    "        raise AzureSyncError(f\"Something went wrong when creating the worksheet. Status code: {response.status_code}, {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File added successfully!\n",
      "01JE235THHXA57JUY5OZDKLYLFN5FJ2CEZ\n",
      "sheet added successfully!\n",
      "Worksheet URL FINAL = https://graph.microsoft.com/v1.0/drives/b!miY83vtC4E6hZVysK2MuIIXS4kkbArdAu4a1mtl-tW_FUmaJ5dR7Sq1_9ZAZ_eG9/items/01JE235THHXA57JUY5OZDKLYLFN5FJ2CEZ/workbook/worksheets/{4ADDF0D8-F0F7-4F6F-8303-3737513886C7}\n",
      "https://graph.microsoft.com/v1.0/drives/b!miY83vtC4E6hZVysK2MuIIXS4kkbArdAu4a1mtl-tW_FUmaJ5dR7Sq1_9ZAZ_eG9/items/01JE235THHXA57JUY5OZDKLYLFN5FJ2CEZ/workbook/worksheets/{4ADDF0D8-F0F7-4F6F-8303-3737513886C7}/tables\n",
      "Could not get the tables. {'error': {'code': 'ItemNotFound', 'message': \"The requested resource doesn't exist.\", 'innerError': {'code': 'itemNotFound', 'message': \"The requested resource doesn't exist.\", 'date': '2023-11-02T09:29:55', 'request-id': 'c2539516-eee4-4310-8f85-7adb14486900', 'client-request-id': 'c2539516-eee4-4310-8f85-7adb14486900'}}}\n"
     ]
    }
   ],
   "source": [
    "write_to_excel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = datetime.datetime.now().strftime(\"%B\")\n",
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_url = write_to_excel(False)\n",
    "\n",
    "def send_message_to_principal():\n",
    "        response = requests.get(url=f\"{table_url}/rows?\", headers=headers)\n",
    "        mc_arrs = [tuple(info) for object_info in response.json()['value'] for info in object_info['values']]\n",
    "        mc_table = pd.DataFrame(data = mc_arrs, columns=[\"name\", \"date\"])\n",
    "        date_today = datetime.datetime.strftime(datetime.datetime.now(), \"%d/%m/%Y\")\n",
    "        mc_today = mc_table.loc[mc_table['date'] == date_today]\n",
    "        mc_tuples = [tuple(new_user) for new_user in mc_today.values]\n",
    "        print(mc_tuples)\n",
    "        message = f\"Staff on MC on {date_today}\\n:\"\n",
    "        for user, date in mc_tuples:\n",
    "                message += f\"{user}\\n\"\n",
    "        return message\n",
    "\n",
    "mc_tuples = send_message_to_principal()\n",
    "mc_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
