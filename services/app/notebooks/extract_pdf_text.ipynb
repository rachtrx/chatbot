{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91740"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, pathlib, fitz\n",
    "fname = \"cc0003.pdf\"\n",
    "with fitz.open(fname) as doc:  # open document\n",
    "    text = chr(12).join([block[4] for page in doc for block in page.get_text(\"blocks\")])\n",
    "# write as a binary file to support non-ASCII characters\n",
    "pathlib.Path(fname + \".txt\").write_bytes(text.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "pdf = fitz.open(\"cc0003.pdf\")\n",
    "counter = 1\n",
    "# for i in range(len(pdf)): # for each page\n",
    "for i in range(5):\n",
    "    page = pdf[i]\n",
    "    images = page.get_images()\n",
    "    for image in images:\n",
    "        base_img = pdf.extract_image(image[0])\n",
    "        print(base_img) # contains a dict about the metadata. The actual data is in the \"image\" key\n",
    "        image_data = base_img[\"image\"]\n",
    "        img = PIL.Image.open(io.BytesIO(image_data))\n",
    "        extension = base_img[\"ext\"]\n",
    "        img.save(open(f\"image{counter}.{extension}\", \"wb\"))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "config = {\n",
    "    'client_id': os.environ.get('CLIENT_ID'),\n",
    "    'client_secret': os.environ.get('CLIENT_SECRET'),\n",
    "    'authority': os.environ.get('AUTHORITY'),\n",
    "    'scope': [os.environ.get('SCOPE')],\n",
    "    'site_id': os.environ.get('SITE_ID'),\n",
    "}\n",
    "\n",
    "headers = {\n",
    "        'Authorization': f'Bearer {os.environ.get(\"ACCESS_TOKEN\")}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "drive_url = f\"https://graph.microsoft.com/v1.0/drives/{os.environ.get('DRIVE_ID')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import sys, pathlib, fitz\n",
    "import io\n",
    "\n",
    "# To analyze the PDF layout and extract text\n",
    "from pdfminer.high_level import extract_pages, extract_text\n",
    "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
    "# To extract text from tables in PDF\n",
    "import pdfplumber\n",
    "# To extract the images from the PDFs\n",
    "from PIL import Image\n",
    "# To perform OCR to extract text from images \n",
    "import pytesseract \n",
    "# To remove the additional created files\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for .pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureSyncError(Exception):\n",
    "\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "\n",
    "def read_pdf(_bytes):\n",
    "\n",
    "    doc = fitz.open(stream=_bytes, filetype=\"pdf\")\n",
    "    text = chr(12).join([block[4] for page in doc for block in page.get_text(\"blocks\")])\n",
    "    doc.close()\n",
    "    text += chr(12)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extraction(element):\n",
    "    # Extracting the text from the in-line text element\n",
    "    line_text = element.get_text()\n",
    "    \n",
    "    # Find the formats of the text\n",
    "    # Initialize the list with all the formats that appeared in the line of text\n",
    "    top_words_dict = {}\n",
    "    for text_line in element:\n",
    "        if isinstance(text_line, LTTextContainer):\n",
    "            # Iterating through each character in the line of text\n",
    "            for character in text_line:\n",
    "                if isinstance(character, LTChar):\n",
    "                    # Append the font size of the character\n",
    "                    if character.size not in top_words_dict:\n",
    "                        top_words_dict[character.size] = [character]\n",
    "                    else:\n",
    "                        # line_formats.append(character.fontname) # TODO maybe bold?\n",
    "                        top_words_dict[character.size].append(character)\n",
    "    \n",
    "    # Return a tuple with the text in each line along with its format\n",
    "    return (line_text, top_words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from scanned pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to crop the image elements from PDFs\n",
    "def crop_image_to_text(element, page):\n",
    "    # Get the coordinates to crop the image from the PDF\n",
    "    [x0, y0, x1, y1] = [element.x0, element.y0, element.x1, element.y1]\n",
    "\n",
    "    # Define the rectangle to crop\n",
    "    clip_rect = fitz.Rect(x0, y0, x1, y1)\n",
    "\n",
    "    # Crop the page to the size of the image\n",
    "    pix = page.get_pixmap(clip=clip_rect)\n",
    "\n",
    "    # Convert the pixmap to an image\n",
    "    img_data = pix.tobytes(\"png\")  # Convert the image to PNG bytes\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract table from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(pdf_path, page_num, table_num):\n",
    "    # Open the pdf file\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    # Find the examined page\n",
    "    table_page = pdf.pages[page_num]\n",
    "    # Extract the appropriate table\n",
    "    table = table_page.extract_tables()[table_num]\n",
    "    return table\n",
    "\n",
    "# Convert table into the appropriate format\n",
    "def table_converter(table):\n",
    "    table_string = ''\n",
    "    # Iterate through each row of the table\n",
    "    for row_num in range(len(table)):\n",
    "        row = table[row_num]\n",
    "        # Remove the line breaker from the wrapped texts\n",
    "        cleaned_row = [item.replace('\\n', ' ') if item is not None and '\\n' in item else 'None' if item is None else item for item in row]\n",
    "        # Convert the table into a string \n",
    "        table_string+=('|'+'|'.join(cleaned_row)+'|'+'\\n')\n",
    "    # Removing the last line break\n",
    "    table_string = table_string[:-1]\n",
    "    return table_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Advantages|Disadvantages|\n",
      "|Avoid discrimination|Not an international law|\n",
      "|Improve the quality of human beings|Lacks the power to legally force any directive|\n",
      "|Set the standard for individuals to be treated equally||\n",
      "|Procedure and framework for governments to protect and promote human rights|None| \n",
      "\n",
      "and Disadvantages of UDHR\n",
      "‘Advantages\n",
      "\n",
      "‘Avoid discrimination\n",
      "Improve the quality of human beings\n",
      "Set the standard for individuals to be treated equally\n",
      "\n",
      "Procedure and framework for governments to protect\n",
      "and promote human rights\n",
      "\n",
      "Countries\n",
      "Apply some from of Human Rights legislations\n",
      "\n",
      " \n",
      "\n",
      "Disadvantages\n",
      "\n",
      "Not an international law\n",
      "\n",
      "Lacks the power to legally force any\n",
      "\fUniversal Declaration of Human Rights (UDHR)\n",
      "Universal Declaration of Human Rights (UDHR)\n",
      "\n",
      "“Adnan tongs ar bom ac eon gnty an rs They are enone mh eason\n",
      "{rs corscaren ana eho omath ow sneer a sat ot rod”\n",
      "\n",
      "ag against craton\n",
      "\n",
      "‘Ont an poten rg, rg rh, ow, pero secu. nd\n",
      "putea paneraton\n",
      "\n",
      "Econom pc ana cain rs an aoe anced ng so\n",
      "‘cory nom std ire tay etucaton od parcgron Pe cat eet 8\n",
      "\n",
      "“Eye rte ssl nd rans ocr wich rh and edo toh\n",
      "‘ih Decaton on be ay an\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\fAdvantages and Disadvantages of UDHR\n",
      "Advantages\n",
      "Disadvantages\n",
      "Avoid discrimination\n",
      "Not an international law\n",
      "Improve the quality of human beings\n",
      "Lacks the power to legally force any directive\n",
      "Set the standard for individuals to be treated equally\n",
      "Procedure and framework for governments to protect\n",
      "and promote human rights\n",
      "Countries\n",
      "Apply some from of Human Rights legislations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code is taken from https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517 by George Stavrakis\n",
    "\n",
    "\n",
    "# Find the PDF path\n",
    "pdf_path = 'cc0003.pdf'\n",
    "\n",
    "# create a PDF file object\n",
    "pdfFileObj = open(pdf_path, 'rb')\n",
    "# create a PDF reader object\n",
    "\n",
    "# Create the dictionary to extract text from each image\n",
    "text_per_page = {}\n",
    "\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# We extract the pages from the PDF\n",
    "for pagenum, page in enumerate(extract_pages(pdf_path)):\n",
    "    \n",
    "    # Initialize the variables needed for the text extraction from the page\n",
    "    fitz_page = doc.load_page(pagenum)\n",
    "    # page_text = []\n",
    "    top_words_dict = {}\n",
    "    # text_from_images = []\n",
    "    # text_from_tables = []\n",
    "    page_content = []\n",
    "    # Initialize the number of the examined tables\n",
    "    table_num = 0\n",
    "    first_element= True\n",
    "    table_extraction_flag= False\n",
    "    # Open the pdf file\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    # Find the examined page\n",
    "    page_tables = pdf.pages[pagenum]\n",
    "    # Find the number of tables on the page\n",
    "    tables = page_tables.find_tables()\n",
    "\n",
    "\n",
    "    # Find all the elements\n",
    "    page_elements = [(element.y1, element) for element in page._objs]\n",
    "    # Sort all the elements as they appear in the page \n",
    "    page_elements.sort(key=lambda a: a[0], reverse=True)\n",
    "\n",
    "    # Find the elements that composed a page\n",
    "    for i, component in enumerate(page_elements):\n",
    "        # Extract the element of the page layout\n",
    "        element = component[1]\n",
    "        \n",
    "        # Check if the element is a text element\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            # Check if the text appeared in a table\n",
    "            if table_extraction_flag == False:\n",
    "                # Use the function to extract the text and format for each text element\n",
    "                (line_text, new_top_words) = text_extraction(element)\n",
    "                # Append the text of each line to the page text\n",
    "                # page_text.append(line_text)\n",
    "                # Append the format for each line containing text\n",
    "                for length in new_top_words:\n",
    "                    if length in top_words_dict:\n",
    "                        top_words_dict[length].extend(new_top_words[length])\n",
    "                    else:\n",
    "                        top_words_dict[length] = new_top_words[length]\n",
    "                page_content.append(line_text)\n",
    "            else:\n",
    "                # Omit the text that appeared in a table\n",
    "                pass\n",
    "\n",
    "        # Check the elements for images\n",
    "        if isinstance(element, LTFigure):\n",
    "            # Crop the image from the PDF\n",
    "            image_text = crop_image_to_text(element, fitz_page)\n",
    "            # text_from_images.append(image_text)\n",
    "            page_content.append(image_text)\n",
    "\n",
    "        # Check the elements for tables\n",
    "        if isinstance(element, LTRect):\n",
    "            # If the first rectangular element\n",
    "            if first_element == True and (table_num + 1) <= len(tables):\n",
    "                # Find the bounding box of the table\n",
    "                lower_side = page.bbox[3] - tables[table_num].bbox[3]\n",
    "                upper_side = element.y1 \n",
    "                # Extract the information from the table\n",
    "                table = extract_table(pdf_path, pagenum, table_num)\n",
    "                # Convert the table information in structured string format\n",
    "                table_string = table_converter(table)\n",
    "                # Append the table string into a list\n",
    "                # text_from_tables.append(table_string)\n",
    "                page_content.append(table_string)\n",
    "                # Set the flag as True to avoid the content again\n",
    "                table_extraction_flag = True\n",
    "                # Make it another element\n",
    "                first_element = False\n",
    "\n",
    "            # Check if we already extracted the tables from the page\n",
    "            if element.y0 >= lower_side and element.y1 <= upper_side:\n",
    "                pass\n",
    "            elif not isinstance(page_elements[i+1][1], LTRect):\n",
    "                table_extraction_flag = False\n",
    "                first_element = True\n",
    "                table_num += 1\n",
    "\n",
    "\n",
    "    # Create the key of the dictionary\n",
    "    dctkey = 'Page_' + str(pagenum)\n",
    "    # Add the list of list as the value of the page key\n",
    "    text_per_page[dctkey] = page_content\n",
    "\n",
    "# Closing the pdf file object\n",
    "doc.close()\n",
    "\n",
    "# Display the content of the page\n",
    "result = ''.join(text_per_page['Page_6'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For .docx and .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word(content):\n",
    "    file_stream = io.BytesIO(content)\n",
    "    doc = docx.Document(file_stream)\n",
    "    text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + chr(12)\n",
    "    text += chr(12)\n",
    "    return text\n",
    "\n",
    "def read_txt(content):\n",
    "    text = content.decode('utf-16')\n",
    "    text += chr(12)\n",
    "    return text\n",
    "\n",
    "def read_document(stream, filename, f_out):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        text = read_pdf(stream)\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        text = read_word(stream)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        text = read_txt(stream)\n",
    "    with pathlib.Path(f_out).open('ab') as file:\n",
    "        file.write(text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_files(url, filename=None):\n",
    "\n",
    "    response = requests.get(url=url, headers=headers)\n",
    "    # response.raise_for_status()\n",
    "    if not 200 <= response.status_code < 300:\n",
    "        raise AzureSyncError(f\"Something went wrong. {response.json()}\")\n",
    "\n",
    "    if filename:\n",
    "        read_document(response.content, filename, \"output.txt\")\n",
    "        print(\"added\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    for value in response.json()['value']:\n",
    "        new_filename = None\n",
    "        relevant = 1\n",
    "        if value['name'].endswith(\".pdf\") or value['name'].endswith(\".docx\") or value['name'].endswith(\".txt\"):\n",
    "            new_filename = value['name']\n",
    "            new_url = value['@microsoft.graph.downloadUrl']\n",
    "        elif value.get('folder'):\n",
    "            new_url = url[:-len(':/children')] + '/' + value['name'] + ':/children'\n",
    "        else:\n",
    "            relevant = 0\n",
    "        \n",
    "        if relevant:\n",
    "            loop_through_files(new_url, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n",
      "added\n"
     ]
    }
   ],
   "source": [
    "temp_url = os.environ.get('TEMP_FOLDER_URL')\n",
    "\n",
    "loop_through_files(temp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
